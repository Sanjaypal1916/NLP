{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67deccf1-73ba-4261-a745-89a781d5e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6860f82c-b3ff-4f6a-b5a9-83be0d3393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "docs = nlp(\"i haven't got the chocolates and that's why im sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79fbb837-47e4-4605-a150-c6958d37591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for token in docs:\n",
    "    print(token.is_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "266e9738-63f7-4995-940d-9401bf802c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f0fda96-a5d9-4e40-b262-4b1026c9b116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c0d2a2b-ec06-454d-940d-cb1089c5c3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c185594f-b95c-43e4-9979-65677d1dd8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d80823d7-1165-408f-b234-e4741343bbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "078737a5-4b60-4422-a619-60e580b7c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19fa0b10-6ff3-441f-8798-b72bc698ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"students.txt\") as f:\n",
    "    text =  f.readlines()\n",
    "\n",
    "text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46421ec0-39fe-4eb5-b75c-df2c83eee1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "624a988b-f2b1-4f61-9a83-a9e2eb0b92f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virat@kohli.com\n",
      "maria@sharapova.com\n",
      "serena@williams.com\n",
      "joe@root.com\n"
     ]
    }
   ],
   "source": [
    "for tokn in docs:\n",
    "    if tokn.like_email:\n",
    "        print(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0efbbca-a040-4dfc-8f5a-5836cc5c540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भैया False False\n",
      "जी False False\n",
      "! False False\n",
      "5000 False True\n",
      "₹ True False\n",
      "उधार False False\n",
      "थे False False\n",
      "वो False False\n",
      "वापस False False\n",
      "देदो False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"hi\")\n",
    "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
    "for token in doc:\n",
    "    print(token, token.is_currency, token.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d11572b-480e-49a4-b38b-7e625fc3ea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[gimme, double, cheese, extra, large, healthy, pizza]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "docs = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "\n",
    "token = [token for token in docs]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a621512-a3e2-4742-86e8-61a609eb5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa1734ba-92a0-4d14-bb74-3cffef1200ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'English' object has no attribute 'tokenzier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenzier\u001b[49m\u001b[38;5;241m.\u001b[39madd_special_case(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgimme\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\n\u001b[0;32m      2\u001b[0m                               {ORTH: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgim\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      3\u001b[0m                               {ORTH: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mme\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \n\u001b[0;32m      4\u001b[0m ])\n\u001b[0;32m      5\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgimme an extra large pizza\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m token \u001b[38;5;241m=\u001b[39m [toke \u001b[38;5;28;01mfor\u001b[39;00m toke \u001b[38;5;129;01min\u001b[39;00m doc]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'English' object has no attribute 'tokenzier'"
     ]
    }
   ],
   "source": [
    "nlp.tokenzier.add_special_case(\"gimme\", [\n",
    "                              {ORTH: \"gim\"},\n",
    "                              {ORTH: \"me\"}, \n",
    "])\n",
    "doc = nlp(\"gimme an extra large pizza\")\n",
    "token = [toke for toke in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "058b57ba-ba13-42fe-8e1e-4d4d58dce837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gim', 'me', 'an', 'extra', 'large', 'pizza']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define special case tokenization for \"gimme\"\n",
    "special_case = [{\"ORTH\": \"gim\"}, {\"ORTH\": \"me\"}]\n",
    "\n",
    "# Add the special case to the tokenizer\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "\n",
    "# Test the tokenizer\n",
    "doc = nlp(\"gimme an extra large pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b4059-89a8-415c-bf56-62b07f3f7ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67deccf1-73ba-4261-a745-89a781d5e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6860f82c-b3ff-4f6a-b5a9-83be0d3393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "docs = nlp(\"i haven't got the chocolates and that's why im sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79fbb837-47e4-4605-a150-c6958d37591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for token in docs:\n",
    "    print(token.is_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "266e9738-63f7-4995-940d-9401bf802c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f0fda96-a5d9-4e40-b262-4b1026c9b116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c0d2a2b-ec06-454d-940d-cb1089c5c3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c185594f-b95c-43e4-9979-65677d1dd8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d80823d7-1165-408f-b234-e4741343bbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "078737a5-4b60-4422-a619-60e580b7c065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19fa0b10-6ff3-441f-8798-b72bc698ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"students.txt\") as f:\n",
    "    text =  f.readlines()\n",
    "\n",
    "text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46421ec0-39fe-4eb5-b75c-df2c83eee1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "624a988b-f2b1-4f61-9a83-a9e2eb0b92f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virat@kohli.com\n",
      "maria@sharapova.com\n",
      "serena@williams.com\n",
      "joe@root.com\n"
     ]
    }
   ],
   "source": [
    "for tokn in docs:\n",
    "    if tokn.like_email:\n",
    "        print(tokn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0efbbca-a040-4dfc-8f5a-5836cc5c540b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भैया False False\n",
      "जी False False\n",
      "! False False\n",
      "5000 False True\n",
      "₹ True False\n",
      "उधार False False\n",
      "थे False False\n",
      "वो False False\n",
      "वापस False False\n",
      "देदो False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"hi\")\n",
    "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
    "for token in doc:\n",
    "    print(token, token.is_currency, token.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d11572b-480e-49a4-b38b-7e625fc3ea01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[gimme, double, cheese, extra, large, healthy, pizza]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "docs = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "\n",
    "token = [token for token in docs]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a621512-a3e2-4742-86e8-61a609eb5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa1734ba-92a0-4d14-bb74-3cffef1200ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[gim, me, an, extra, large, pizza]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.add_special_case(\"gimme\", [\n",
    "                              {ORTH: \"gim\"},\n",
    "                              {ORTH: \"me\"}, \n",
    "])\n",
    "doc = nlp(\"gimme an extra large pizza\")\n",
    "token = [toke for toke in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "058b57ba-ba13-42fe-8e1e-4d4d58dce837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gim', 'me', 'an', 'extra', 'large', 'pizza']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define special case tokenization for \"gimme\"\n",
    "special_case = [{\"ORTH\": \"gim\"}, {\"ORTH\": \"me\"}]\n",
    "\n",
    "# Add the special case to the tokenizer\n",
    "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
    "\n",
    "# Test the tokenizer\n",
    "doc = nlp(\"gimme an extra large pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "053b4059-89a8-415c-bf56-62b07f3f7ef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m token \u001b[38;5;241m=\u001b[39m [toe \u001b[38;5;28;01mfor\u001b[39;00m toe \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msent\u001b[49m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'sent'"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "token = [toe for toe in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d04f811c-877c-4fed-84ff-b5fda298aea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a78027d2-ba45-4139-8a7e-4d9e82ec43b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1f9513ea580>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b94e7eb1-d980-49d1-a9e9-2ae9a8513e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x1f9513ea580>)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76c11e28-8ad0-4b44-9ea6-0157989e7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for token in doc.sents:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ecdcbc9-81b6-4cd1-a725-c53d11fd7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b396a77b-010a-4b96-b492-71b117ca41ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[http://www.data.gov/,\n",
       " http://www.science,\n",
       " http://data.gov.uk/.,\n",
       " http://www3.norc.org/gss+website/,\n",
       " http://www.europeansocialsurvey.org/.]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = nlp(text)\n",
    "ans = []\n",
    "for tok in docs:\n",
    "    if tok.like_url:\n",
    "        ans.append(tok)\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5419be9a-15a8-43b0-a818-ff0255c82614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "docs = nlp(transactions)\n",
    "for toke in docs:\n",
    "    if toke.is_currency:\n",
    "        k = toke.i - 1\n",
    "        print(docs[k].text +\" \"+toke.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f79c9685-9d06-49d4-ad2e-15589b2f688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "docs = nlp(transactions)\n",
    "for toke in docs.sents:\n",
    "    toke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c8612584-3707-4359-909d-2139df73568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony gave two $ to Peter, Bruce gave 500 € to Steve"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5a0cd1-fa50-41fe-b996-315185ba8499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
